Using backend: pytorch
main start at this time 1648229503.9179106
#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

in feats:  100
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 2.0242919921875 GB
    Memory Allocated: 0.0006527900695800781  GigaBytes
Max Memory Allocated: 0.0006527900695800781  GigaBytes

The real block id is  2
get_global_graph_edges_ids_block function  spend 0.6473071575164795
random selection method range initialization spend 0.014872550964355469
time for parepare:  0.36478114128112793
local_output_nid generation:  0.04712224006652832
local_in_edges_tensor generation:  0.16690516471862793
mini_batch_src_global generation:  0.21335959434509277
r_  generation:  3.1980204582214355
local_output_nid generation:  0.04798412322998047
local_in_edges_tensor generation:  0.14080047607421875
mini_batch_src_global generation:  0.2696690559387207
r_  generation:  3.3388586044311523
----------------------check_connections_block total spend ----------------------------- 8.834611177444458
generate_one_block  9.29490065574646
generate_one_block  4.086179494857788
The real block id is  1
get_global_graph_edges_ids_block function  spend 3.1891865730285645
gen group dst list time:  0.08080482482910156
time for parepare:  0.4739687442779541
local_output_nid generation:  0.49774670600891113
local_in_edges_tensor generation:  1.7434566020965576
mini_batch_src_global generation:  1.9229817390441895
r_  generation:  24.638659238815308
local_output_nid generation:  0.6596686840057373
local_in_edges_tensor generation:  1.8113365173339844
mini_batch_src_global generation:  2.6679155826568604
r_  generation:  24.918954849243164
----------------------check_connections_block total spend ----------------------------- 69.06259608268738
generate_one_block  34.0007164478302
generate_one_block  33.27977466583252
The real block id is  0
get_global_graph_edges_ids_block function  spend 3.3385441303253174
gen group dst list time:  0.20104551315307617
time for parepare:  0.5129585266113281
local_output_nid generation:  0.7247943878173828
local_in_edges_tensor generation:  2.1319830417633057
mini_batch_src_global generation:  2.014857053756714
r_  generation:  27.14624047279358
local_output_nid generation:  0.7395403385162354
local_in_edges_tensor generation:  2.106031656265259
mini_batch_src_global generation:  2.8765745162963867
r_  generation:  27.132216453552246
----------------------check_connections_block total spend ----------------------------- 75.9175717830658
generate_one_block  36.8780152797699
generate_one_block  36.26264452934265
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 2.0242919921875 GB
    Memory Allocated: 0.0006527900695800781  GigaBytes
Max Memory Allocated: 0.0006527900695800781  GigaBytes

connection checking time:  144.98016786575317
block generation total time  140.42115092277527
average batch blocks generation time:  70.21057546138763
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 3.9481201171875 GB
    Memory Allocated: 1.8607606887817383  GigaBytes
Max Memory Allocated: 1.8607606887817383  GigaBytes

Traceback (most recent call last):
  File "pseudo_mini_batch_range_products_sage.py", line 455, in <module>
    main()
  File "pseudo_mini_batch_range_products_sage.py", line 451, in main
    best_test = run(args, device, data)
  File "pseudo_mini_batch_range_products_sage.py", line 276, in run
    batch_pred = model(blocks, batch_inputs)#------------*
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/graph_partition_multi_layers/pseudo_mini_batch_full_batch/SAGE/graphsage_model_products.py", line 48, in forward
    x = layer(block, x)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 258, in forward
    graph.update_all(msg_fn, self._lstm_reducer)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/heterograph.py", line 4849, in update_all
    ndata = core.message_passing(g, message_func, reduce_func, apply_node_func)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 327, in message_passing
    msgdata = invoke_gsddmm(g, mfunc)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 245, in invoke_gsddmm
    z = op(graph, x)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/ops/sddmm.py", line 169, in copy_u
    return gsddmm(g, 'copy_lhs', x, None)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/ops/sddmm.py", line 75, in gsddmm
    g._graph, op, lhs_data, rhs_data, lhs_target, rhs_target)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/backend/pytorch/sparse.py", line 512, in gsddmm
    return GSDDMM.apply(gidx, op, lhs_data, rhs_data, lhs_target, rhs_target)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/cuda/amp/autocast_mode.py", line 213, in decorate_fwd
    return fwd(*args, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/backend/pytorch/sparse.py", line 256, in forward
    out = _gsddmm(gidx, op, X, Y, lhs_target, rhs_target)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/sparse.py", line 328, in _gsddmm
    out = F.zeros(out_shp, dtype, ctx)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py", line 220, in zeros
    return th.zeros(shape, dtype=dtype, device=ctx)
RuntimeError: CUDA out of memory. Tried to allocate 24.33 GiB (GPU 0; 23.62 GiB total capacity; 1.86 GiB already allocated; 19.68 GiB free; 1.86 GiB reserved in total by PyTorch)
