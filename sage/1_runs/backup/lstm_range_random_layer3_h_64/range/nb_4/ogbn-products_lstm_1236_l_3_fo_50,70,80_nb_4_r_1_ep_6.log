Using backend: pytorch
main start at this time 1648301719.753543
#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

in feats:  100
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 2.0242919921875 GB
    Memory Allocated: 0.0006527900695800781  GigaBytes
Max Memory Allocated: 0.0006527900695800781  GigaBytes

The real block id is  2
get_global_graph_edges_ids_block function  spend 0.5865449905395508
range selection method range initialization spend 0.028386831283569336
time for parepare:  0.369748592376709
local_output_nid generation:  0.012860774993896484
local_in_edges_tensor generation:  0.08544325828552246
mini_batch_src_global generation:  0.11178112030029297
r_  generation:  1.552917718887329
local_output_nid generation:  0.013573408126831055
local_in_edges_tensor generation:  0.05590033531188965
mini_batch_src_global generation:  0.13643813133239746
r_  generation:  1.6742312908172607
local_output_nid generation:  0.013442039489746094
local_in_edges_tensor generation:  0.05648350715637207
mini_batch_src_global generation:  0.11757707595825195
r_  generation:  1.744696855545044
local_output_nid generation:  0.013483047485351562
local_in_edges_tensor generation:  0.04784131050109863
mini_batch_src_global generation:  0.1269540786743164
r_  generation:  1.8194031715393066
----------------------check_connections_block total spend ----------------------------- 8.926482200622559
generate_one_block  7.185338735580444
generate_one_block  2.1512234210968018
generate_one_block  2.1203806400299072
generate_one_block  2.094440221786499
The real block id is  1
get_global_graph_edges_ids_block function  spend 3.5379955768585205
gen group dst list time:  0.12436556816101074
time for parepare:  0.45966291427612305
local_output_nid generation:  0.20046615600585938
local_in_edges_tensor generation:  1.110762596130371
mini_batch_src_global generation:  1.625272274017334
r_  generation:  20.110957384109497
local_output_nid generation:  0.3496997356414795
local_in_edges_tensor generation:  1.39668869972229
mini_batch_src_global generation:  2.3588695526123047
r_  generation:  20.961057901382446
local_output_nid generation:  0.365584135055542
local_in_edges_tensor generation:  1.6960930824279785
mini_batch_src_global generation:  2.3187263011932373
r_  generation:  20.22612953186035
local_output_nid generation:  0.3727383613586426
local_in_edges_tensor generation:  2.2581422328948975
mini_batch_src_global generation:  2.0744454860687256
r_  generation:  20.401055097579956
----------------------check_connections_block total spend ----------------------------- 112.75187397003174
generate_one_block  28.39720892906189
generate_one_block  28.062988758087158
generate_one_block  28.758901119232178
generate_one_block  28.128403186798096
The real block id is  0
get_global_graph_edges_ids_block function  spend 3.3016648292541504
gen group dst list time:  0.33005690574645996
time for parepare:  0.5083940029144287
local_output_nid generation:  0.47365498542785645
local_in_edges_tensor generation:  1.607506513595581
mini_batch_src_global generation:  1.9903440475463867
r_  generation:  25.95425772666931
local_output_nid generation:  0.7079699039459229
local_in_edges_tensor generation:  2.1196036338806152
mini_batch_src_global generation:  2.9146528244018555
r_  generation:  25.915716648101807
local_output_nid generation:  0.7532987594604492
local_in_edges_tensor generation:  1.8766648769378662
mini_batch_src_global generation:  2.6012954711914062
r_  generation:  26.405222177505493
local_output_nid generation:  0.7677497863769531
local_in_edges_tensor generation:  1.908313274383545
mini_batch_src_global generation:  2.9385128021240234
r_  generation:  26.229592084884644
----------------------check_connections_block total spend ----------------------------- 145.02347040176392
generate_one_block  35.54672431945801
generate_one_block  35.17069220542908
generate_one_block  35.20420742034912
generate_one_block  36.2347469329834
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 2.0242919921875 GB
    Memory Allocated: 0.0006527900695800781  GigaBytes
Max Memory Allocated: 0.0006527900695800781  GigaBytes

connection checking time:  257.77534437179565
block generation total time  255.50387287139893
average batch blocks generation time:  63.87596821784973
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 3.8504638671875 GB
    Memory Allocated: 1.7543883323669434  GigaBytes
Max Memory Allocated: 1.7543883323669434  GigaBytes

Traceback (most recent call last):
  File "pseudo_mini_batch_range_products_sage.py", line 455, in <module>
    main()
  File "pseudo_mini_batch_range_products_sage.py", line 451, in main
    best_test = run(args, device, data)
  File "pseudo_mini_batch_range_products_sage.py", line 276, in run
    batch_pred = model(blocks, batch_inputs)#------------*
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/graph_partition_multi_layers/pseudo_mini_batch_full_batch/SAGE/graphsage_model_products.py", line 48, in forward
    x = layer(block, x)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/nn/pytorch/conv/sageconv.py", line 258, in forward
    graph.update_all(msg_fn, self._lstm_reducer)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/heterograph.py", line 4849, in update_all
    ndata = core.message_passing(g, message_func, reduce_func, apply_node_func)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 327, in message_passing
    msgdata = invoke_gsddmm(g, mfunc)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 245, in invoke_gsddmm
    z = op(graph, x)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/ops/sddmm.py", line 169, in copy_u
    return gsddmm(g, 'copy_lhs', x, None)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/ops/sddmm.py", line 75, in gsddmm
    g._graph, op, lhs_data, rhs_data, lhs_target, rhs_target)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/backend/pytorch/sparse.py", line 512, in gsddmm
    return GSDDMM.apply(gidx, op, lhs_data, rhs_data, lhs_target, rhs_target)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/cuda/amp/autocast_mode.py", line 213, in decorate_fwd
    return fwd(*args, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/backend/pytorch/sparse.py", line 256, in forward
    out = _gsddmm(gidx, op, X, Y, lhs_target, rhs_target)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/sparse.py", line 328, in _gsddmm
    out = F.zeros(out_shp, dtype, ctx)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py", line 220, in zeros
    return th.zeros(shape, dtype=dtype, device=ctx)
RuntimeError: CUDA out of memory. Tried to allocate 24.11 GiB (GPU 0; 23.62 GiB total capacity; 1.75 GiB already allocated; 19.77 GiB free; 1.76 GiB reserved in total by PyTorch)
